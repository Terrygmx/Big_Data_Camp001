 # 作业一
 
## 思路：
对每个文件进行wordCount，结果的k,v是（单词、词频）。把结果的pair RDD 的values 用map转换为一个集合，此时k，v为（单词，（文件名、词频））
再使用一个空的RDD作来收集结果，使用reduceByKey把每个文件的结果收集起来。
 
 ## 核心代码
 ```scala
 val lineRDD: RDD[String] = sc.textFile("file://"+path)
			val wordRDD: RDD[String] = lineRDD.flatMap(line => line.split(" "))
			val cleanWordRDD: RDD[String] = wordRDD.filter(word => !word.equals(""))
			// 把RDD元素转换为（Key，Value）的形式
			val cntKvRDD: RDD[(String, Integer)] = cleanWordRDD.map(word => (word,1))
			// 按照单词做累加
			val wordCountRDD: RDD[(String, Integer)] = cntKvRDD.reduceByKey((x, y) => x + y)
			// wordCountRDD 元素转换为 a: {(2,1)} 的形式
			val transKvRDD: RDD[(String, List[(String,Integer)])] = wordCountRDD.mapValues(cnt => List((fn,cnt)))
			allKvRDD=allKvRDD.union(transKvRDD)
			
			
	// 把来自各单词的全部结果合并
		val result: RDD[(String, List[(String,Integer)])] = allKvRDD.reduceByKey((x, y) => x ++ y)
 ```
 
 ## 提交任务
 ```sh
 spark-submit --class com.terry.revertIndex.RevertIndex week6-homework-1.0-SNAPSHOT.jar /home/student5/terry/homework/week7/input  /home/student5/terry/homework/week7/output
 ```
 
 ## 结果
 
 (is,List((0,2), (1,1), (2,1)))
(a,List((2,1)))
(what,List((0,1), (1,1)))
(banana,List((2,1)))
(it,List((0,2), (1,1), (2,1)))
